{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e9599e76",
      "metadata": {
        "id": "e9599e76",
        "outputId": "d97906a7-4fa3-4847-fc12-4e4b465a2c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting filetype\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype\n",
            "Successfully installed filetype-1.2.0\n"
          ]
        }
      ],
      "source": [
        " !pip install opencv-python numpy\n",
        " !pip install filetype\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import cv2\n",
        "import os\n",
        "import filetype\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "dWbPysZ88PWH"
      },
      "id": "dWbPysZ88PWH",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The model architecture\n",
        "# download from: https://drive.google.com/open?id=1kiusFljZc9QfcIYdU2s7xrtWHTraHwmW\n",
        "AGE_MODEL = 'deploy_age.prototxt'\n",
        "# The model pre-trained weights\n",
        "# download from: https://drive.google.com/open?id=1kWv0AjxGSN0g31OeJa02eBGM0R_jcjIl\n",
        "AGE_PROTO = 'age_net.caffemodel'\n",
        "# Each Caffe Model impose the shape of the input image also image preprocessing is required like mean\n",
        "# substraction to eliminate the effect of illunination changes\n",
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "# Represent the 8 age classes of this CNN probability layer\n",
        "AGE_INTERVALS = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)',\n",
        "                 '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
        "# download from: https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "FACE_PROTO = \"deploy.prototxt.txt\"\n",
        "# download from: https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
        "FACE_MODEL = \"res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
        "# Initialize frame size\n",
        "frame_width = 1280\n",
        "frame_height = 720\n",
        "# load face Caffe model\n",
        "face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n",
        "# Load age prediction model\n",
        "age_net = cv2.dnn.readNetFromCaffe(AGE_MODEL, AGE_PROTO)"
      ],
      "metadata": {
        "id": "1Ys4r7vz8UJ4"
      },
      "id": "1Ys4r7vz8UJ4",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_faces(frame, confidence_threshold=0.5):\n",
        "    \"\"\"Returns the box coordinates of all detected faces\"\"\"\n",
        "    # convert the frame into a blob to be ready for NN input\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n",
        "    # set the image as input to the NN\n",
        "    face_net.setInput(blob)\n",
        "    # perform inference and get predictions\n",
        "    output = np.squeeze(face_net.forward())\n",
        "    # initialize the result list\n",
        "    faces = []\n",
        "    # Loop over the faces detected\n",
        "    for i in range(output.shape[0]):\n",
        "        confidence = output[i, 2]\n",
        "        if confidence > confidence_threshold:\n",
        "            box = output[i, 3:7] * np.array([frame_width, frame_height, frame_width, frame_height])\n",
        "            # convert to integers\n",
        "            start_x, start_y, end_x, end_y = box.astype(np.int)\n",
        "            # widen the box a little\n",
        "            start_x, start_y, end_x, end_y = start_x - \\\n",
        "                10, start_y - 10, end_x + 10, end_y + 10\n",
        "            start_x = 0 if start_x < 0 else start_x\n",
        "            start_y = 0 if start_y < 0 else start_y\n",
        "            end_x = 0 if end_x < 0 else end_x\n",
        "            end_y = 0 if end_y < 0 else end_y\n",
        "            # append to our list\n",
        "            faces.append((start_x, start_y, end_x, end_y))\n",
        "    return faces"
      ],
      "metadata": {
        "id": "FLOP03348T_h"
      },
      "id": "FLOP03348T_h",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_img(title, img):\n",
        "    \"\"\"Displays an image on screen and maintains the output until the user presses a key\"\"\"\n",
        "    # Display Image on screen\n",
        "    cv2.imshow(title, img)\n",
        "    # Mantain output until user presses a key\n",
        "    cv2.waitKey(0)\n",
        "    # Destroy windows when user presses a key\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "PqcNRptp8YsX"
      },
      "id": "PqcNRptp8YsX",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimal_font_scale(text, width):\n",
        "    \"\"\"Determine the optimal font scale based on the hosting frame width\"\"\"\n",
        "    for scale in reversed(range(0, 60, 1)):\n",
        "        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n",
        "        new_width = textSize[0][0]\n",
        "        if (new_width <= width):\n",
        "            return scale/10\n",
        "    return 1\n",
        "\n",
        "# from: https://stackoverflow.com/questions/44650888/resize-an-image-without-distortion-opencv\n",
        "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
        "    # initialize the dimensions of the image to be resized and\n",
        "    # grab the image size\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "    # if both the width and height are None, then return the\n",
        "    # original image\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "    # check to see if the width is None\n",
        "    if width is None:\n",
        "        # calculate the ratio of the height and construct the\n",
        "        # dimensions\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "    # otherwise, the height is None\n",
        "    else:\n",
        "        # calculate the ratio of the width and construct the\n",
        "        # dimensions\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "    # resize the image\n",
        "    return cv2.resize(image, dim, interpolation = inter)"
      ],
      "metadata": {
        "id": "GtmzlURx8eEj"
      },
      "id": "GtmzlURx8eEj",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_age(input_path: str):\n",
        "    \"\"\"Predict the age of the faces showing in the image\"\"\"\n",
        "    # Read Input Image\n",
        "    img = cv2.imread(input_path)\n",
        "    # Take a copy of the initial image and resize it\n",
        "    frame = img.copy()\n",
        "    if frame.shape[1] > frame_width:\n",
        "        frame = image_resize(frame, width=frame_width)\n",
        "    faces = get_faces(frame)\n",
        "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
        "        face_img = frame[start_y: end_y, start_x: end_x]\n",
        "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
        "        blob = cv2.dnn.blobFromImage(\n",
        "            image=face_img, scalefactor=1.0, size=(227, 227), \n",
        "            mean=MODEL_MEAN_VALUES, swapRB=False\n",
        "        )\n",
        "        # Predict Age\n",
        "        age_net.setInput(blob)\n",
        "        age_preds = age_net.forward()\n",
        "        print(\"=\"*30, f\"Face {i+1} Prediction Probabilities\", \"=\"*30)\n",
        "        for i in range(age_preds[0].shape[0]):\n",
        "            print(f\"{AGE_INTERVALS[i]}: {age_preds[0, i]*100:.2f}%\")\n",
        "        i = age_preds[0].argmax()\n",
        "        age = AGE_INTERVALS[i]\n",
        "        age_confidence_score = age_preds[0][i]\n",
        "        # Draw the box\n",
        "        label = f\"Age:{age} - {age_confidence_score*100:.2f}%\"\n",
        "        print(label)\n",
        "        # get the position where to put the text\n",
        "        yPos = start_y - 15\n",
        "        while yPos < 15:\n",
        "            yPos += 15\n",
        "        # write the text into the frame\n",
        "        cv2.putText(frame, label, (start_x, yPos),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), thickness=2)\n",
        "        # draw the rectangle around the face\n",
        "        cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), color=(255, 0, 0), thickness=2)\n",
        "    # Display processed image\n",
        "    display_img('Age Estimator', frame)\n",
        "    # save the image if you want\n",
        "    # cv2.imwrite(\"predicted_age.jpg\", frame)"
      ],
      "metadata": {
        "id": "8OfNc-HP8gB7"
      },
      "id": "8OfNc-HP8gB7",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Parsing command line arguments entered by user\n",
        "    import sys\n",
        "    image_path = sys.argv[1]\n",
        "    predict_age(image_path)"
      ],
      "metadata": {
        "id": "ojlEuIUZ8hhV",
        "outputId": "acacb71a-3998-4bbb-9c3b-f261e9def76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "id": "ojlEuIUZ8hhV",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-14b300992e9c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredict_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-96ad26cffa27>\u001b[0m in \u001b[0;36mpredict_age\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Take a copy of the initial image and resize it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mframe_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}